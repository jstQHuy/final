import os
from utils.prompt import PentestAgentPrompt
from utils.dir_class import judge_class
from llama_index.llms.openai import OpenAI
from llama_index.core import (
    Settings,
    load_index_from_storage,
    StorageContext,
    SimpleDirectoryReader,
    SimpleKeywordTableIndex,
    SummaryIndex
)
from llama_index.core.schema import IndexNode
from llama_index.core.storage.index_store import SimpleIndexStore
from llama_index.core.query_engine import RetrieverQueryEngine
import dotenv
from utils.vote import get_final_scr
import json
import asyncio
import signal
from concurrent.futures import ThreadPoolExecutor, TimeoutError
from functools import wraps

import concurrent.futures
import threading
import time
import multiprocessing

default_otpt = {
    "note": "timeout"
}

def timeout(seconds, default_value=None):
    """a timeout decorator for process"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            def worker(result_queue, *args, **kwargs):
                try:
                    result = func(*args, **kwargs)
                    result_queue.put(result)
                except Exception as e:
                    result_queue.put({"error": str(e)})
            
            result_queue = multiprocessing.Queue()
            process = multiprocessing.Process(
                target=worker, 
                args=(result_queue, *args), 
                kwargs=kwargs
            )
            process.start()
            process.join(timeout=seconds)
            
            if process.is_alive():
                print(f"Function {func.__name__} timed out after {seconds} seconds, terminating...")
                process.terminate()
                process.join()
                return default_value
            else:
                if not result_queue.empty():
                    return result_queue.get()
                else:
                    return default_value
        return wrapper
    return decorator


class DocHandler:
    """ Given a data directory, DocHandler takes care of loading, indexing, and storing the data.
        Returns vector, summary, and keyword indices keyed by services
    """
    query_eng = None
    summary_dict = {}

    def __init__(self) -> None:

        pass
    
    def vul_analysis(self, cve:str, output_dir:str):
        if "exploit" not in cve:    
            doc_dir = f"{output_dir}/{cve}/Google"
            code_dirs = {
                "ExploitDB": f"{output_dir}/{cve}/ExploitDB",
                "GitHub": f"{output_dir}/{cve}/GitHub"
            }
        else:
            doc_dir = f"{output_dir}/Google"
            code_dirs = {
                "ExploitDB": f"{output_dir}/ExploitDB",
                "GitHub": f"{output_dir}/GitHub"
            }
        
        result = {}
        result["code"] = {}
        result["doc"] = {}
        
        # process code directories (ExploitDB and GitHub)
        for code_source, code_dir in code_dirs.items():
            if os.path.exists(code_dir) and len(os.listdir(code_dir)) > 0:
                if code_source not in result["code"]:
                    result["code"][code_source] = {
                        "lang_class": {},
                        "score": {}
                    }
                    otpt = {}
                
                subdirs = [f.name for f in os.scandir(code_dir) if f.is_dir()]
                for repo in subdirs:
                    repo_dir = os.path.join(code_dir, repo)
                    print(f"repo or dir: {repo}")
                    entries = [entry for entry in os.listdir(repo_dir) if not entry.startswith('.')]
                    if not os.path.exists(repo_dir) or len(entries) == 0:
                        continue
                    
                    code_reader = SimpleDirectoryReader(repo_dir, recursive=True, num_files_limit=10)
                    code_documents = code_reader.load_data()
                    repo_summary_index = SummaryIndex.from_documents(code_documents)
                    repo_query_engine = repo_summary_index.as_query_engine()

                    result["code"][code_source]["lang_class"][repo] = judge_class(repo_dir)

                    score, otpt = self.get_direct_score_from_code(repo_query_engine)
                    result["code"][code_source]["score"][repo] = score

                    if "exploit" in cve:
                        filename_otpt = f"{output_dir}/otptEC_from_code_{repo}.json"
                    else:
                        filename_otpt = f"{output_dir}/{cve}/otptEC_from_code_{repo}.json"
                    with open(filename_otpt, 'w') as f:
                        json.dump(otpt, f, indent=4)
        
        # process document directories
        if os.path.exists(doc_dir) and len(os.listdir(doc_dir)) > 0:
            doc_reader = SimpleDirectoryReader(doc_dir, recursive=True, num_files_limit=10)
            doc_documents = doc_reader.load_data()
            doc_summary_index = SummaryIndex.from_documents(doc_documents)
            doc_query_engine = doc_summary_index.as_query_engine()

            score = self.get_direct_score_from_doc(doc_query_engine)
            result["doc"]["score"]= score

        return result
    
    @timeout(300, default_value=(5, default_otpt))
    def get_direct_score_from_code(self, query_engine):
        score = 0
        otpt = ""
        try:
            score, otpt = get_final_scr(str(query_engine.query(PentestAgentPrompt.direct_judge_code)))
        except Exception as e:
            print(e)

        return int(score), otpt

    def get_direct_score_from_doc(self, query_engine):
        score = 0
        try:
            score = get_final_scr(str(query_engine.query(PentestAgentPrompt.direct_judge_doc)))
        except Exception as e:
            print(e)

        return int(score)

    def create_index(self, topic_dir:str, summary_prompt:str, keyword:str):
        list_subfolders_with_paths = [f.path for f in os.scandir(topic_dir) if f.is_dir()]
        counter = 0
        repo_index_nodes = []
        keyword_index_dir_by_keyword = os.path.join(os.getenv("INDEX_STORAGE_DIR"),
                                                    "keyword_repos", keyword)
        repos_keyword_index = None
        
        if not os.path.exists(keyword_index_dir_by_keyword):
            for repo_dir in list_subfolders_with_paths:
                items = os.listdir(repo_dir)
                visible_items = [item for item in items if not item.startswith('.')]
                if visible_items:
                    print(repo_dir)

                    reader = SimpleDirectoryReader(repo_dir, recursive=True)
                    documents = reader.load_data()
                    repo_summary_index = SummaryIndex.from_documents(documents)
                    repo_query_engine = repo_summary_index.as_query_engine()
                    summary_txt = str(repo_query_engine.query(summary_prompt))
                    print(summary_txt)
                    self.summary_dict[repo_dir] = summary_txt

                    new_metadata = {
                        "repo path": str(repo_dir),}

                    repo_index_node = IndexNode(
                        text = summary_txt,
                        metadata = new_metadata,
                        index_id=str(counter)
                    )
                    repo_index_nodes.append(repo_index_node)

                    counter+=1

            repos_keyword_index = SimpleKeywordTableIndex(objects=repo_index_nodes)
            storage_context = StorageContext.from_defaults(index_store=SimpleIndexStore())
            repos_keyword_index.storage_context.persist(persist_dir=keyword_index_dir_by_keyword)
            
        else:
            storage_context = StorageContext.from_defaults(persist_dir=keyword_index_dir_by_keyword)
            repos_keyword_index = load_index_from_storage(storage_context)

        keyword_retriever = repos_keyword_index.as_retriever(verbose=True)


        self.query_eng = RetrieverQueryEngine.from_args(keyword_retriever, verbose=True)

    def query(self, query_content):
        response = self.query_eng.query(query_content)
        return response
    
    def get_repo_summary(self, repo_dir):
        return self.summary_dict[repo_dir]
    
    def get_repo_summaryDict(self):
        return self.summary_dict

def main():
    dotenv.load_dotenv()
    Settings.llm = OpenAI(temperature=0, model="gpt-4o")
    doc_dir = 'resources/CVE-2019-1609/GitHub'
    summary_prompt = PentestAgentPrompt.repo_summary
    doc_handler = DocHandler()
    doc_handler.create_index(doc_dir, summary_prompt, "CVE-2019-1609_github")
    service = "Cisco"
    version = ""
    query_content = f"Clearly list out paths of all relevant repositories that contains exploit poc applicable to {service} version {version}\
                    and provide the reasons to support each selection. \
                    To compare versions, you can compare their version numbers in left-to-right order. For example, 7.4.0 is an earlier version than 8.2.3.\
                    Make the selections by checking whether {version} is within the applicable version of the exploit. Only consider the paths mentioned in the context."
    res = doc_handler.query(query_content)
    print("response:")
    print(res)

if __name__ == "__main__":
    main()